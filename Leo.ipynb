{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Challenge: Smart meter is coming\n",
    "by BCM Energy - PlanÃ¨te OUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import holidays\n",
    "import math as mt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Activation, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    'provided_data_and_metric/X_train_6GWGSxz.csv',\n",
    ")\n",
    "Y_train = pd.read_csv(\n",
    "    'provided_data_and_metric/y_train_2G60rOL.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.consumption[X_train.consumption.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataImputer and YImputer are custom trasformers we have built to deal with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            X.drop('Unnamed: 9', axis = 1, inplace = True)\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "        X = X.interpolate(method='linear').fillna(method='bfill')\n",
    "        X.time_step = pd.to_datetime(X.time_step)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.interpolate(method='linear').fillna(method='bfill')\n",
    "#         X.index = pd.to_datetime(X.index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = DataImputer()\n",
    "yi = YImputer()\n",
    "X_train = di.transform(X=X_train)\n",
    "Y_train = yi.transform(X=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.consumption.fillna(method=\"ffill\", inplace=True)\n",
    "# X_test.consumption.fillna(method=\"ffill\", inplace=True)\n",
    "# Y_train.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"time_step\"] = pd.to_datetime(X_train[\"time_step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_holidays = holidays.France()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT DELETE THIS PLEASE OR WE DO NOT GET IS_HOLIDAYS WORKING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in X_train.time_step.dt.date:\n",
    "    if i in fr_holidays:\n",
    "        c+=1\n",
    "        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extra features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we also want to add day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"weekday\"] = X_train.time_step.dt.dayofweek\n",
    "X_train[\"month\"] = X_train.time_step.dt.month\n",
    "X_train[\"hour\"] = X_train.time_step.dt.hour\n",
    "X_train[\"is_weekend\"] = (X_train[\"weekday\"] > 4)*1  \n",
    "X_train[\"is_holidays\"] = (X_train.time_step.dt.date.isin(fr_holidays))*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is on average more consumption during weekends, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"consumption\", \"is_weekend\"]].groupby(\"is_weekend\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"consumption\", \"weekday\"]].groupby(\"weekday\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(0,7), y=\"consumption\", data=X_train.groupby(\"weekday\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"consumption\", \"month\"]].groupby(\"month\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant drop in consumption over the summer! We do not have data for January, February. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(3,13), y=\"consumption\", data=X_train.groupby(\"month\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the afternoon, the most consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(0,24), y=\"consumption\", data=X_train.groupby(\"hour\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holidays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.consumption.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"consumption\", \"is_holidays\"]].groupby(\"is_holidays\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the big difference in consumption, it looks like the data belongs to a city in France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[[\"consumption\", \"is_holidays\"]].groupby(\"is_holidays\").std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2,2, figsize=(15,15))\n",
    "# axs[0,0].scatter(X_train.consumption[Y_train.washing_machine > 0], Y_train.washing_machine[Y_train.washing_machine > 0], c=\"red\")\n",
    "# axs[0,0].scatter(X_train.consumption[Y_train.washing_machine == 0], Y_train.washing_machine[Y_train.washing_machine == 0], c=\"blue\")\n",
    "# axs[0,1].scatter(X_train.consumption, Y_train.fridge_freezer )\n",
    "# axs[1,0].scatter(X_train.consumption, Y_train.TV )\n",
    "# axs[1,1].scatter(X_train.consumption, Y_train.kettle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Analyzing the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekday:\n",
    "- People enjoy using the Washing Machine on Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.groupby(X_train.weekday).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Month:\n",
    "- Significant increase in the use of the Washing Machine and the Kettle in November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.groupby(X_train.month).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.groupby(X_train.is_weekend).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hour:\n",
    "- Washing Machine used late evening\n",
    "- TV from the evening\n",
    "- Kettle in the afternoon around Tea Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.groupby(X_train.hour).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holidays:\n",
    "- Who wants to do a Washing Machine while on holidays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.groupby(X_train.is_holidays).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the data, these features can be added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"is_breakfast\"] = ((X_train.hour>5) & (X_train.hour<9))*1 \n",
    "X_train[\"is_teatime\"] = ((X_train.hour>16) & (X_train.hour<20))*1 \n",
    "X_train[\"is_TVtime\"] = ((X_train.hour>17) & (X_train.hour<23))*1\n",
    "# X_train[\"is_working_hour\"] = ((X_train.hour>7) & (X_train.hour<19))*1\n",
    "X_train[\"is_night\"] = ((X_train.hour>0) & (X_train.hour<7))*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put all in a transformer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmenter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X[\"time_step\"] = pd.to_datetime(X[\"time_step\"])\n",
    "        X[\"weekday\"] = X.time_step.dt.dayofweek\n",
    "        X[\"month\"] = X.time_step.dt.month\n",
    "        X[\"hour\"] = X.time_step.dt.hour\n",
    "        X[\"is_weekend\"] = (X[\"weekday\"] > 4)*1  \n",
    "        X[\"is_holidays\"] = (X.time_step.dt.date.isin(fr_holidays))*1\n",
    "        \n",
    "        X[\"is_breakfast\"] = ((X.hour>5) & (X.hour<9))*1 \n",
    "        X[\"is_teatime\"] = ((X.hour>16) & (X.hour<20))*1 \n",
    "        X[\"is_TVtime\"] = ((X.hour>17) & (X.hour<23))*1\n",
    "        # X_train[\"is_working_hour\"] = ((X_train.hour>7) & (X_train.hour<19))*1\n",
    "        X[\"is_night\"] = ((X.hour>0) & (X.hour<7))*1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression, a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MultiOutputRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html) consists of fitting one regressor per target. \n",
    "\n",
    "This is a simple strategy for extending regressors that do not natively support multi-target regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cold months only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = Y_train.loc[(X_train.month<4) | (X_train.month>8)]\n",
    "# X_train = X_train.loc[(X_train.month<4) | (X_train.month>8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = MultiOutputRegressor(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    X_train.drop('time_step', axis=1), Y_train.drop('time_step', axis=1), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at all the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([i.coef_ for i in regressor.estimators_], columns=X_train.columns[1:], index=Y_train.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_pred, columns=y_train.columns)\n",
    "pred[\"time_step\"] = X_train.time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric used on the website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_nilm(dataframe_y_true, dataframe_y_pred):\n",
    "    score = 0.0\n",
    "    test = dataframe_y_true['washing_machine']\n",
    "    pred = dataframe_y_pred['washing_machine']\n",
    "    score += mt.sqrt(sum((pred.values - test.values)**2)/len(test))*5.55\n",
    "    test = dataframe_y_true['fridge_freezer']\n",
    "    pred = dataframe_y_pred['fridge_freezer']\n",
    "    score += mt.sqrt(sum((pred.values - test.values)**2)/len(test))*49.79\n",
    "    test = dataframe_y_true['TV']\n",
    "    pred = dataframe_y_pred['TV']\n",
    "    score += mt.sqrt(sum((pred.values - test.values)**2)/len(test))*14.57\n",
    "    test = dataframe_y_true['kettle']\n",
    "    pred = dataframe_y_pred['kettle']\n",
    "    score += mt.sqrt(sum((pred.values - test.values)**2)/len(test))*4.95\n",
    "    score /= 74.86\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_nilm(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\n",
    "    'provided_data_and_metric/X_test_c2uBt2s.csv', \n",
    ")\n",
    "X_test.drop('Unnamed: 9', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save time for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = X_test[\"time_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = di.transform(X=X_test)\n",
    "ag = DataAugmenter()\n",
    "X_test = ag.transform(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_pred, columns=Y_train.columns[1:])\n",
    "pred= pd.concat([time, pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(\"test_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a custom OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.all_possible_hours = np.arange(0, 24)\n",
    "        self.all_possible_weekdays = np.arange(0, 7)\n",
    "        self.all_possible_months = np.arange(1, 13)\n",
    "        self.ohe_hours = OneHotEncoder(drop=\"first\")\n",
    "        self.ohe_weekdays = OneHotEncoder(drop=\"first\")\n",
    "        self.ohe_months = OneHotEncoder(drop=\"first\")\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.ohe_hours.fit(self.all_possible_hours.reshape(-1,1))\n",
    "        self.ohe_weekdays.fit(self.all_possible_weekdays.reshape(-1,1))\n",
    "        self.ohe_months.fit(self.all_possible_months.reshape(-1,1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        hours = pd.DataFrame(self.ohe_hours.transform(X.hour.values.reshape(-1,1)).toarray(), \n",
    "                             columns=[\"hour_\"+str(i) for i in range(1, 24)])\n",
    "        weekdays = pd.DataFrame(self.ohe_weekdays.transform(X.weekday.values.reshape(-1,1)).toarray(), \n",
    "                             columns=[\"weekday_\"+str(i) for i in range(1, 7)])\n",
    "        months = pd.DataFrame(self.ohe_months.transform(X.month.values.reshape(-1,1)).toarray(), \n",
    "                             columns=[\"month_\"+str(i) for i in range(2, 13)])\n",
    "        X = pd.concat([X, hours, weekdays, months], axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = MyOneHotEncoder()\n",
    "oh.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = oh.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    'provided_data_and_metric/X_train_6GWGSxz.csv',\n",
    ")\n",
    "Y_train = pd.read_csv(\n",
    "    'provided_data_and_metric/y_train_2G60rOL.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't work if I uncomment. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline([\n",
    "    (\n",
    "        '1',\n",
    "        DataImputer()\n",
    "    ),\n",
    "    (\n",
    "        '2',\n",
    "        DataAugmenter()\n",
    "    ),\n",
    "    (\n",
    "        '3',\n",
    "        MyOneHotEncoder()\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting if appliance is on or off\n",
    "There is a huge difference in consumption when an appliance is on or off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.fridge_freezer[Y_train.fridge_freezer != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.fridge_freezer.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kettle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.kettle[Y_train.kettle != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.kettle.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Washing Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.washing_machine[Y_train.washing_machine != 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.washing_machine.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TV is always on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train.TV != 0).sum() == len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.TV.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(15,15))\n",
    "axs[0,0].scatter(X_train.consumption[Y_train.washing_machine > 0], Y_train.washing_machine[Y_train.washing_machine > 0], c=\"red\")\n",
    "axs[0,0].scatter(X_train.consumption[Y_train.washing_machine == 0], Y_train.washing_machine[Y_train.washing_machine == 0], c=\"blue\")\n",
    "axs[0,1].scatter(X_train.consumption, Y_train.fridge_freezer )\n",
    "axs[1,0].scatter(X_train.consumption, Y_train.TV )\n",
    "axs[1,1].scatter(X_train.consumption, Y_train.kettle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    'provided_data_and_metric/X_train_6GWGSxz.csv',\n",
    ")\n",
    "Y_train = pd.read_csv(\n",
    "    'provided_data_and_metric/y_train_2G60rOL.csv',\n",
    ")\n",
    "X_test = pd.read_csv(\n",
    "    'provided_data_and_metric/X_test_c2uBt2s.csv', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.set_index(\"time_step\", inplace=True)\n",
    "Y_train.set_index(\"time_step\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_train.iloc[-1, :])\n",
    "Y_train = Y_train.append(Y_train.iloc[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            X.drop('Unnamed: 9', axis = 1, inplace = True)\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "        X = X.interpolate(method='linear').fillna(method='bfill')\n",
    "        X.index = pd.to_datetime(X.index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.interpolate(method='linear').fillna(method='bfill')\n",
    "#         X.index = pd.to_datetime(X.index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmenter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X[\"time_step\"] = pd.to_datetime(X[\"time_step\"])\n",
    "        X[\"weekday\"] = X.time_step.dt.dayofweek\n",
    "        X[\"month\"] = X.time_step.dt.month\n",
    "        X[\"hour\"] = X.time_step.dt.hour\n",
    "        X[\"is_weekend\"] = (X[\"weekday\"] > 4)*1  \n",
    "        X[\"is_holidays\"] = (X.time_step.dt.date.isin(fr_holidays))*1\n",
    "        \n",
    "        X[\"is_breakfast\"] = ((X.hour>5) & (X.hour<9))*1 \n",
    "        X[\"is_teatime\"] = ((X.hour>16) & (X.hour<20))*1 \n",
    "        X[\"is_TVtime\"] = ((X.hour>17) & (X.hour<23))*1\n",
    "        # X_train[\"is_working_hour\"] = ((X_train.hour>7) & (X_train.hour<19))*1\n",
    "        X[\"is_night\"] = ((X.hour>0) & (X.hour<7))*1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataFormatter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X.set_index(\"time_step\", inplace=True)\n",
    "        X = X.append(X.iloc[-1, :])\n",
    "        nb_col = X.shape[1]\n",
    "        return X.values.reshape((int(X_rnn.shape[0]/60), 60, nb_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Pipeline([\n",
    "    (\n",
    "        '1',\n",
    "        DataImputer()\n",
    "    ),\n",
    "    (\n",
    "        '2',\n",
    "        DataAugmenter()\n",
    "    ),\n",
    "    (\n",
    "        '3',\n",
    "        RNNDataFormatter()\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Pipeline([\n",
    "    (\n",
    "        '1',\n",
    "        YImputer()\n",
    "    ),\n",
    "    (\n",
    "        '2',\n",
    "        RNNDataFormatter()\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = p1.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = p2.transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = X[:6000, :], Y[:6000, :, :]\n",
    "x_valid, y_valid = X[6000:, :], Y[6000:, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(20, return_sequences=True, input_shape=[None, 14]),\n",
    "    SimpleRNN(20, return_sequences=True),\n",
    "    SimpleRNN(4, return_sequences=True)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(x_train, y_train, epochs=10,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "#     plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_valid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO** (before running code below):\n",
    "- Add ColumnTransformer, to avoid scaling categorical features.\n",
    "- Add DataAugmenter in the pipeline\n",
    "- Check if RNNDataFormatter still works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue**: The RNN returns output from sigmoid, hence between (-1, 1).\n",
    "\n",
    "**Idea**: Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify RNNDataFormatter to make it work with np.arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataFormatter(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X.set_index(\"time_step\", inplace=True)\n",
    "        X = X.append(X.iloc[-1, :])\n",
    "        nb_col = X.shape[1]\n",
    "        X = X.reshape((int(X.shape[0]/60), 60, nb_col))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit StandardScaler before, gives error in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Pipeline([\n",
    "        (\n",
    "        '1',\n",
    "        DataImputer()\n",
    "    ),\n",
    "    (\n",
    "        '2',\n",
    "        scaler_x\n",
    "    ),\n",
    "    (\n",
    "        '3',\n",
    "        RNNDataFormatter()\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Pipeline([\n",
    "    (\n",
    "        '1',\n",
    "        YImputer()\n",
    "    ),\n",
    "    (\n",
    "        '2',\n",
    "        scaler_y\n",
    "    ),\n",
    "    (\n",
    "        '3',\n",
    "        RNNDataFormatter()\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = p1.transform(X_train)\n",
    "y_scaled = p2.transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_scaled shape is {x_scaled.shape}\")\n",
    "print(f\"y_scaled shape is {y_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_scaled[:6000, :], y_scaled[:6000, :, :]\n",
    "x_valid, y_valid = x_scaled[6000:, :], y_scaled[6000:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(20, return_sequences=True, input_shape=[None, 8]),\n",
    "    SimpleRNN(20, return_sequences=True),\n",
    "    SimpleRNN(4, return_sequences=True)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(x_train, y_train, epochs=20,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 4)) #shape is now (360000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_trans.iloc[:360000, :], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "y_pred[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
